{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dee584d8-ce0e-45e3-ad8a-04644d8f2a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb7e3f28-31cb-43ea-86e6-398a918dddd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_data = open(\"rating_10k_synths.csv\", \"r\").readlines()\n",
    "\n",
    "train_test_percentage = 0.90\n",
    "cutoff = int(train_test_percentage * len(synth_data))\n",
    "\n",
    "# stupid extract data from csv\n",
    "# organized by:\n",
    "#  song_name | num of plays | [values...]\n",
    "lines = [l.replace('\\n', '').split('\\t') for l in synth_data]\n",
    "\n",
    "random.shuffle(lines)\n",
    "\n",
    "my_x = [[float(i) for i in l[2:]] for l in lines]\n",
    "my_y = [float(l[1]) for l in lines]\n",
    "my_y_max = np.amax(my_y)\n",
    "\n",
    "my_y = [(y/my_y_max)**(0.4) for y in my_y]\n",
    "\n",
    "# splice dataset\n",
    "train_x = my_x[:cutoff]\n",
    "train_y = my_y[:cutoff]\n",
    "test_x = my_x[cutoff:]\n",
    "test_y = my_y[cutoff:]\n",
    "\n",
    "# prepare tensors\n",
    "tensor_train_x = torch.Tensor(train_x) # transform to torch tensor\n",
    "tensor_train_y = torch.Tensor(train_y)\n",
    "tensor_test_x = torch.Tensor(test_x) # transform to torch tensor\n",
    "tensor_test_y = torch.Tensor(test_y)\n",
    "\n",
    "train_dataset = TensorDataset(tensor_train_x,tensor_train_y) # create your datset\n",
    "train_dataloader = DataLoader(train_dataset) # create your dataloader\n",
    "test_dataset = TensorDataset(tensor_test_x,tensor_test_y) # create your datset\n",
    "test_dataloader = DataLoader(test_dataset) # create your dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c281a90b-0c38-4f2e-8830-ab78d2cac9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.210e+02, 5.110e+02, 7.260e+02, 1.271e+03, 7.020e+02, 4.410e+02,\n",
       "        3.470e+02, 2.720e+02, 1.940e+02, 1.540e+02, 1.390e+02, 6.800e+01,\n",
       "        5.900e+01, 4.800e+01, 3.100e+01, 9.000e+00, 7.000e+00, 6.000e+00,\n",
       "        3.000e+00, 1.000e+00]),\n",
       " array([0.00190523, 0.04883092, 0.09575661, 0.14268231, 0.189608  ,\n",
       "        0.23653369, 0.28345939, 0.33038508, 0.37731077, 0.42423647,\n",
       "        0.47116216, 0.51808785, 0.56501355, 0.61193924, 0.65886494,\n",
       "        0.70579063, 0.75271632, 0.79964202, 0.84656771, 0.8934934 ,\n",
       "        0.9404191 ]),\n",
       " <BarContainer object of 20 artists>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 1, sharey=True, tight_layout=True)\n",
    "\n",
    "# We can set the number of bins with the *bins* keyword argument.\n",
    "axs.hist(train_y, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e31de980-ba60-49c8-b1dd-402b2183af69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a single tensor\n",
    "def test_model(target):\n",
    "    #X = torch.rand(1, 527, 1, device=device)\n",
    "    #target = cutoff + 1\n",
    "    X = torch.tensor(my_x[target])\n",
    "    start = time.perf_counter_ns()\n",
    "    #print(X.shape)\n",
    "    logits = model(X)\n",
    "    end = time.perf_counter_ns()\n",
    "    print(f\"Testing took: {(end - start)/1000000}ms\")\n",
    "    print(f\"index[{target}] : {logits[0]:>0.4f} vs {my_y[target]:>0.4f}\")\n",
    "    #print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c6bd177-7f67-4efa-967c-1c00df7720d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_model(model):\n",
    "    print(f\"Model structure: {model}\\n\\n\")\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d16f3437-e0b8-45a0-b1ef-a4528285764a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 1000 == 500:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            #print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "#pdist = torch.nn.PairwiseDistance(p=2)\n",
    "def validate_epoch(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset) // int(1)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct, errors = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            #print(f\"Got pred: {pred.sum().item()}\\tfor y: {y[0]}\")\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            errors += (abs(pred.sum().item() - y[0]))\n",
    "    test_loss /= num_batches\n",
    "    errors /= size\n",
    "    correct = 1 - errors\n",
    "    if progress % 1 == 0 or progress == 0:\n",
    "        print(\n",
    "            f\"Epoch {str(progress).zfill(2)}  \"\n",
    "            f\"Accuracy: {(100 * correct):>0.1f}%  \"\n",
    "            f\"Avg loss: {test_loss:>8f}  [{'X'*int(50*correct)}{'-'*int(50*(1-correct))}]\"\n",
    "        )\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b9e8209-bd91-413e-b4c3-1e78d719c973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_model(expmodel):\n",
    "    dummy_input = torch.randn(1, 1, 527)\n",
    "    torch.onnx.export(expmodel,\n",
    "                 dummy_input,\n",
    "                 \"tridonn.onnx\",\n",
    "                 verbose=True,\n",
    "                 input_names=[\"dense1\"],\n",
    "                 output_names=[\"outact\"],\n",
    "                 export_params=True,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "68c1588c-f82c-4cd7-8e72-36424197130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_file(filename):\n",
    "    rate_file = open(filename, \"r\").readlines()\n",
    "    rate_lines = [l.replace('\\n', '').split('\\t') for l in rate_file]\n",
    "\n",
    "    my_test_x = [[float(i) for i in l[1:]] for l in rate_lines[1:]]\n",
    "    song_names = [l[0] for l in rate_lines[1:]]\n",
    "    \n",
    "    print(\"Song ratings: [0-1]\")\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for i in range(len(my_test_x)):\n",
    "        X = torch.tensor(my_test_x[i])\n",
    "        song_name = song_names[i].split('/')[-1]\n",
    "        logits = model(X)\n",
    "        #end = time.perf_counter_ns()\n",
    "        #print(f\"Testing took: {(end - start)/1000000}ms\")\n",
    "        #print(f\"index[{target}] : {logits[0]:>0.4f} vs {my_y[target]:>0.4f}\")\n",
    "        results[song_name] = float(logits[0])\n",
    "\n",
    "        #print(f\"{song_name} = {logits[0]:>0.4f}\")\n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3dd17e2a-0ef8-4ebc-a06b-c9e7af429ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      "Testing took: 0.254513ms\n",
      "index[201] : 0.4922 vs 0.6294\n",
      "Epoch 00  Accuracy: 70.8%  Avg loss: 0.098720  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX--------------]\n",
      "\n",
      "Training:\n",
      "Epoch 01  Accuracy: 89.3%  Avg loss: 0.019760  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX-----]\n",
      "Epoch 02  Accuracy: 89.4%  Avg loss: 0.019617  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX-----]\n",
      "Epoch 03  Accuracy: 89.4%  Avg loss: 0.019550  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX-----]\n",
      "Training took: 10648.497242ms\n",
      "\n",
      "Testing:\n",
      "Testing took: 0.311548ms\n",
      "index[201] : 0.1999 vs 0.6294\n",
      "Testing took: 0.49145ms\n",
      "22751\n"
     ]
    }
   ],
   "source": [
    "#model = NeuralNetwork().to(device)\n",
    "\n",
    "N0 = 527\n",
    "N1 = 10\n",
    "N2 = 1\n",
    "NX = 1\n",
    "\n",
    "model = nn.Sequential(OrderedDict([\n",
    "    ('dense1', nn.Linear(N0, N1)),\n",
    "    ('act1', nn.ReLU()),\n",
    "    ('dense2', nn.Linear(N1, N2)),\n",
    "    #('act2', nn.ReLU()),\n",
    "    #('output', nn.Linear(N2, NX)),\n",
    "    ('outact', nn.Sigmoid()),\n",
    "]))\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0004)\n",
    "epochs = 3\n",
    "progress = 0\n",
    "\n",
    "target = 201\n",
    "\n",
    "# before training (sanity check)\n",
    "print(\"Before:\")\n",
    "test_model(target)\n",
    "\n",
    "loss = validate_epoch(test_dataloader, model, loss_fn)\n",
    "\n",
    "train_time = 0\n",
    "print(\"\\nTraining:\")\n",
    "\n",
    "for i in range(epochs):\n",
    "    progress += 1\n",
    "    start = time.perf_counter_ns()\n",
    "    train_epoch(train_dataloader, model, loss_fn, optimizer)\n",
    "    train_time += time.perf_counter_ns() - start\n",
    "    loss = validate_epoch(test_dataloader, model, loss_fn)\n",
    "    \n",
    "    # eval\n",
    "    #values = rate_file(\"my_fun_playlist.csv\")\n",
    "    #print('\\n'.join([f\"{f[0]}: {f[1]}\" for f in sorted(values.items(), key=lambda x: -x[1])[:5]]))\n",
    "    #print('\\n'.join([f\"{f[0]}: {f[1]}\" for f in sorted(values.items(), key=lambda x: -x[1])[-5:]]))\n",
    "    #session.report(dict(loss=loss))\n",
    "\n",
    "print(f\"Training took: {(train_time)/1000000}ms\")\n",
    "\n",
    "print(\"\\nTesting:\")\n",
    "start = time.perf_counter_ns()\n",
    "test_model(target)\n",
    "end = time.perf_counter_ns()\n",
    "print(f\"Testing took: {(end - start)/1000000}ms\")\n",
    "    \n",
    "torch.save(model.state_dict(), 'tridonn')\n",
    "print(os.path.getsize('tridonn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "be9df99f-b383-4269-ba2a-9d132e7806e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%dense1 : Float(1, 1, 527, strides=[527, 527, 1], requires_grad=0, device=cpu),\n",
      "      %dense1.bias : Float(10, strides=[1], requires_grad=1, device=cpu),\n",
      "      %dense2.bias : Float(1, strides=[1], requires_grad=1, device=cpu),\n",
      "      %onnx::MatMul_13 : Float(527, 10, strides=[1, 527], requires_grad=0, device=cpu),\n",
      "      %onnx::MatMul_14 : Float(10, 1, strides=[1, 10], requires_grad=0, device=cpu)):\n",
      "  %/dense1/MatMul_output_0 : Float(1, 1, 10, strides=[10, 10, 1], device=cpu) = onnx::MatMul[onnx_name=\"/dense1/MatMul\"](%dense1, %onnx::MatMul_13), scope: torch.nn.modules.container.Sequential::/torch.nn.modules.linear.Linear::dense1 # /home/tristan/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %/dense1/Add_output_0 : Float(1, 1, 10, strides=[10, 10, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/dense1/Add\"](%dense1.bias, %/dense1/MatMul_output_0), scope: torch.nn.modules.container.Sequential::/torch.nn.modules.linear.Linear::dense1 # /home/tristan/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %/act1/Relu_output_0 : Float(1, 1, 10, strides=[10, 10, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/act1/Relu\"](%/dense1/Add_output_0), scope: torch.nn.modules.container.Sequential::/torch.nn.modules.activation.ReLU::act1 # /home/tristan/.local/lib/python3.10/site-packages/torch/nn/functional.py:1453:0\n",
      "  %/dense2/MatMul_output_0 : Float(1, 1, 1, strides=[1, 1, 1], device=cpu) = onnx::MatMul[onnx_name=\"/dense2/MatMul\"](%/act1/Relu_output_0, %onnx::MatMul_14), scope: torch.nn.modules.container.Sequential::/torch.nn.modules.linear.Linear::dense2 # /home/tristan/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %/dense2/Add_output_0 : Float(1, 1, 1, strides=[1, 1, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/dense2/Add\"](%dense2.bias, %/dense2/MatMul_output_0), scope: torch.nn.modules.container.Sequential::/torch.nn.modules.linear.Linear::dense2 # /home/tristan/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %outact : Float(1, 1, 1, strides=[1, 1, 1], requires_grad=1, device=cpu) = onnx::Sigmoid[onnx_name=\"/outact/Sigmoid\"](%/dense2/Add_output_0), scope: torch.nn.modules.container.Sequential::/torch.nn.modules.activation.Sigmoid::outact # /home/tristan/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py:294:0\n",
      "  return (%outact)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# export for onnx\n",
    "export_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99081a14-7c72-412f-b79f-9a0d774ca3e7",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fcc888b0-0478-4d6c-b1bb-3b09c6e0c459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song ratings: [0-1]\n",
      "Testing took: 26.420665ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'3670232 - Passion Pit - Manners - Sleepyhead.m4a.wav': 0.24408693611621857,\n",
       " '35410166 - Galantis - Runaway (U & I) - Runaway (U & I).m4a.wav': 0.24288801848888397,\n",
       " '74886176 - Portugal. The Man - Woodstock - Tidal Wave.m4a.wav': 0.23303045332431793,\n",
       " '85108589 - Digitalism - Zdar C1u6 - Holograms.m4a.wav': 0.2330245077610016,\n",
       " '198746918 - Die Antwoord - Donker Mag - Strunk.m4a.wav': 0.2321891039609909,\n",
       " '226480299 - Flume - TheSoundYouNeed, Vol. 1 - Drop The Game.m4a.wav': 0.2302871197462082,\n",
       " '49990992 - Glass Animals - ZABA (Deluxe) - Gooey.m4a.wav': 0.22990146279335022,\n",
       " '59881210 - KAYTRANADA - 99.9% - GOT IT GOOD.m4a.wav': 0.22944870591163635,\n",
       " '82440278 - Flume - Flume- Deluxe Edition - Insane (L D R U Remix).m4a.wav': 0.22871091961860657,\n",
       " '64145296 - Glass Animals - How To Be A Human Being - The Other Side Of Paradise.m4a.wav': 0.22756868600845337,\n",
       " '54329308 - Miike Snow - Genghis Khan - Genghis Khan.m4a.wav': 0.2275334894657135,\n",
       " '74447704 - alt-J - RELAXER - Deadcrush.m4a.wav': 0.22662946581840515,\n",
       " \"47696798 - Tame Impala - Currents - 'Cause I'm A Man.m4a.wav\": 0.2263134866952896,\n",
       " '91642505 - Tame Impala - Currents - Let It Happen.m4a.wav': 0.22622334957122803,\n",
       " '62306349 - Chet Faker - Built On Glass - Talk Is Cheap.m4a.wav': 0.22548088431358337,\n",
       " '30209249 - Glass Animals - ZABA - Toes.m4a.wav': 0.22381655871868134,\n",
       " '30209244 - Glass Animals - ZABA - Pools.m4a.wav': 0.2227729707956314,\n",
       " '58085927 - Spoon - Gimme Fiction (Deluxe Edition) - I Turn My Camera On.m4a.wav': 0.22212548553943634,\n",
       " '55130775 - The Beatles - Magical Mystery Tour (Remastered) - Strawberry Fields Forever (Remastered 2009).m4a.wav': 0.22207148373126984,\n",
       " '1404367 - Gorillaz - Demon Days - DARE.m4a.wav': 0.22157317399978638,\n",
       " '106894980 - Tame Impala - Indie Hits - The Less I Know The Better.m4a.wav': 0.2215677946805954,\n",
       " '51487647 - Deluxe - Stachelight - Shoes.m4a.wav': 0.22151686251163483,\n",
       " '67261060 - Justice - Woman - Stop.m4a.wav': 0.2215128242969513,\n",
       " '61325600 - M83 - Do It, Try It (Remixes) - Do It, Try It.m4a.wav': 0.22142262756824493,\n",
       " '68924145 - Sônge - SÔNGE - Now.m4a.wav': 0.221397265791893,\n",
       " '64145298 - Glass Animals - How To Be A Human Being - Poplar St.m4a.wav': 0.22122491896152496,\n",
       " '261267584 - Quinn XCII - Full Circle - Full Circle.m4a.wav': 0.22122150659561157,\n",
       " '45514347 - A$AP Rocky - AT.LONG.LAST.A$AP - L$D.m4a.wav': 0.22102519869804382,\n",
       " '64240234 - Young Thug - JEFFERY - Wyclef Jean.m4a.wav': 0.2199983447790146,\n",
       " '34394933 - alt-J - Summer Remix EP - Fitzpleasure (The Internet of Odd Future Remix).m4a.wav': 0.21978025138378143,\n",
       " '20331019 - Portugal. The Man - Evil Friends - Smile.m4a.wav': 0.21967104077339172,\n",
       " '34395402 - alt-J - An Awesome Wave - Tessellate.m4a.wav': 0.21964918076992035,\n",
       " '56719687 - James Supercave - Better Strange - Better Strange.m4a.wav': 0.21795988082885742,\n",
       " '47696790 - Tame Impala - Currents - Nangs.m4a.wav': 0.21795938909053802,\n",
       " '67803361 - Post Malone - Stoney (Deluxe) - White Iverson.m4a.wav': 0.21734833717346191,\n",
       " '67581302 - The Weeknd - Starboy - Sidewalks.m4a.wav': 0.21614471077919006,\n",
       " '44534954 - Joywave - How Do You Feel Now- - Tongues.m4a.wav': 0.2156132161617279,\n",
       " '81108221 - Childish Gambino - Hip Hop Love Songs - Redbone.m4a.wav': 0.2153349667787552,\n",
       " '245042536 - Childish Gambino - -Awaken, My Love!- - Me and Your Mama.m4a.wav': 0.21503815054893494,\n",
       " '58823196 - M83 - Junk - Go! (feat. Mai Lan).m4a.wav': 0.21460774540901184,\n",
       " '68266840 - HOMESHAKE - Midnight Snack - Faded.m4a.wav': 0.21353000402450562,\n",
       " '245072670 - Robert Delong - Just Movement - Global Concepts.m4a.wav': 0.2134089469909668,\n",
       " '67005669 - Jain - Zanaka (Deluxe) - Makeba.m4a.wav': 0.21235717833042145,\n",
       " '55010268 - Anderson .Paak - Malibu - Come Down.m4a.wav': 0.21232575178146362,\n",
       " '28098322 - Tame Impala - Lonerism - Feels Like We Only Go Backwards.m4a.wav': 0.2117961347103119,\n",
       " '19357874 - Depeche Mode - Delta Machine - Angel.m4a.wav': 0.21130114793777466,\n",
       " '209237078 - J. Cole - 2014 Forest Hills Drive - No Role Modelz.m4a.wav': 0.2110186219215393,\n",
       " '94370579 - Masego - Lady Lady - Tadow.m4a.wav': 0.21092663705348969,\n",
       " '1317017 - MGMT - Oracular Spectacular - The Youth.m4a.wav': 0.21089473366737366,\n",
       " '209237077 - J. Cole - 2014 Forest Hills Drive - G.O.M.D.m4a.wav': 0.2103693187236786,\n",
       " '59126789 - DRAM - Broccoli (feat. Lil Yachty) - Broccoli.m4a.wav': 0.20968198776245117,\n",
       " '49413742 - Stereophonics - Graffiti on the Train - Graffiti on the Train.m4a.wav': 0.2096400260925293,\n",
       " '16300003 - Passion Pit - Gossamer - Take a Walk.m4a.wav': 0.20928452908992767,\n",
       " '4379996 - Tame Impala - Tame Impala - H.F.G.W (Canyons Drunken Rage).m4a.wav': 0.2092607319355011,\n",
       " '4071507 - Ween - The Mollusk - Mutilated Lips.m4a.wav': 0.20884110033512115,\n",
       " '20420859 - Yael Naim - Yael Naïm - New Soul.m4a.wav': 0.20877861976623535,\n",
       " '27132247 - Mac DeMarco - Salad Days - Chamber Of Reflection.m4a.wav': 0.20841345191001892,\n",
       " '97138788 - Arcade Fire - Reflektor - Reflektor.m4a.wav': 0.20838429033756256,\n",
       " '19708979 - Kid Cudi - Indicud - Just What I Am (Explicit Version).m4a.wav': 0.20756207406520844,\n",
       " '3209964 - Deltron 3030 - Deltron 3030 - 3030.m4a.wav': 0.20695650577545166,\n",
       " \"55163291 - The Beatles - Sgt. Pepper's Lonely Hearts Club Band (Remastered) - Lucy In The Sky With Diamonds (Remastered 2009).m4a.wav\": 0.20685231685638428,\n",
       " '67261056 - Justice - Woman - Safe and Sound.m4a.wav': 0.2062639445066452,\n",
       " '48493039 - The Fratellis - Eyes Wide, Tongue Tied (Deluxe) - Medusa in Chains.m4a.wav': 0.20623867213726044,\n",
       " '52099774 - BØRNS - Dopamine - Electric Love.m4a.wav': 0.2060108333826065,\n",
       " '114492503 - Kendrick Lamar - Section.80 - Rigamortus.m4a.wav': 0.20523183047771454,\n",
       " '4875690 - Kanye West - My Beautiful Dark Twisted Fantasy - Runaway.m4a.wav': 0.20493432879447937,\n",
       " '36336297 - Led Zeppelin - Led Zeppelin IV (Deluxe Edition) - Stairway to Heaven (Remaster).m4a.wav': 0.2040933072566986,\n",
       " '3254300 - Jimi Hendrix - Axis- Bold As Love - Little Wing.m4a.wav': 0.20394013822078705,\n",
       " '46813305 - Everything Everything - Get To Heaven (Deluxe) - No Reptiles.m4a.wav': 0.20362380146980286,\n",
       " '1550549 - Daft Punk - Discovery - Harder, Better, Faster, Stronger.m4a.wav': 0.2033383995294571,\n",
       " '35470515 - Kendrick Lamar - good kid, m.A.A.d city (Deluxe) - m.A.A.d city.m4a.wav': 0.20308776199817657,\n",
       " '114492495 - Kendrick Lamar - Section.80 - A.D.H.D.m4a.wav': 0.20224550366401672,\n",
       " '19357873 - Depeche Mode - Delta Machine - Welcome to My World.m4a.wav': 0.20200642943382263,\n",
       " '64230759 - Like - Songs Made While High - Mushroom Clouds.m4a.wav': 0.2017614245414734,\n",
       " '81466340 - Columbine - Clubbing For Columbine - Les prélis.m4a.wav': 0.20173388719558716,\n",
       " \"22248426 - Arctic Monkeys - AM - Why'd You Only Call Me When You're High-.m4a.wav\": 0.20009678602218628,\n",
       " '62247183 - Cold War Kids - Behave Yourself - Audience Of One.m4a.wav': 0.199917733669281,\n",
       " '52973776 - Led Zeppelin - Mothership (Remastered) - No Quarter (Remaster).m4a.wav': 0.19948649406433105,\n",
       " '49413744 - Stereophonics - Graffiti on the Train - Take Me.m4a.wav': 0.19922040402889252,\n",
       " '58990516 - Radiohead - OK Computer - Karma Police.m4a.wav': 0.199021115899086,\n",
       " '95553647 - Theo Lawrence - Homemade Lemonade (Deluxe Version) - Heaven to Me.m4a.wav': 0.1990000307559967,\n",
       " '20331015 - Portugal. The Man - Evil Friends - Waves.m4a.wav': 0.19849732518196106,\n",
       " '2213221 - Ratatat - Ratatat - Seventeen Years.m4a.wav': 0.19704435765743256,\n",
       " '49990990 - Glass Animals - ZABA (Deluxe) - Black Mambo.m4a.wav': 0.1970381885766983,\n",
       " '75144330 - Radiohead - OK Computer OKNOTOK 1997 2017 - Exit Music (For A Film) (Remastered).m4a.wav': 0.19598084688186646,\n",
       " '186242383 - Chris Isaak - Best Of Chris Isaak - Wicked Game.m4a.wav': 0.19355922937393188,\n",
       " '71715607 - alt-J - In Cold Blood - In Cold Blood.m4a.wav': 0.19336871802806854,\n",
       " '95667937 - Part Company - Babar - Babar.m4a.wav': 0.19331666827201843,\n",
       " '37559136 - The Rapture - In The Grace Of Your Love - Deluxe Edition - It Takes Time to Be a Man.m4a.wav': 0.19329160451889038,\n",
       " '34395403 - alt-J - An Awesome Wave - Breezeblocks.m4a.wav': 0.19298607110977173,\n",
       " '55391798 - Pink Floyd - Wish You Were Here - Shine On You Crazy Diamond (Pts. 1-5).m4a.wav': 0.19279876351356506,\n",
       " '157276 - Air - 10 000 Hz Legend - Electronic Performers.m4a.wav': 0.19250239431858063,\n",
       " '183084655 - Modest Mouse - This Is a Long Drive for Someone with Nothing to Think About - Dramamine.m4a.wav': 0.18965637683868408,\n",
       " \"30349476 - Led Zeppelin - Led Zeppelin (Deluxe Edition) - Babe I'm Gonna Leave You (Remaster).m4a.wav\": 0.1885923594236374,\n",
       " '32823114 - Underworld - 1992 - 2012 - Born Slippy (Nuxx).m4a.wav': 0.18803763389587402,\n",
       " '22951454 - Yellow Ostrich - The Mistress - WHALE.m4a.wav': 0.1871763914823532,\n",
       " \"20329300 - The National - Trouble Will Find Me - Don't Swallow the Cap.m4a.wav\": 0.18713340163230896,\n",
       " '61471 - Modest Mouse - Good News For People Who Love Bad News - Float On.m4a.wav': 0.18452996015548706,\n",
       " '19327519 - Mac DeMarco - 2 - Ode to Viceroy.m4a.wav': 0.18378163874149323,\n",
       " '119804589 - Clap Your Hands Say Yeah - Looking for Alaska (Music from the Original Series) - The Skin of My Yellow Country Teeth.m4a.wav': 0.18277958035469055,\n",
       " '3821704 - LCD Soundsystem - This Is Happening - Dance Yrself Clean.m4a.wav': 0.18188396096229553,\n",
       " '1317016 - MGMT - Oracular Spectacular - Weekend Wars.m4a.wav': 0.18156176805496216,\n",
       " '1493038 - Daft Punk - Aerodynamic - Aerodynamic.m4a.wav': 0.18135513365268707,\n",
       " '55391426 - Pink Floyd - Atom Heart Mother - Fat Old Sun.m4a.wav': 0.18064279854297638,\n",
       " '65622697 - Manwolves - Sauce - Sauce.m4a.wav': 0.18061913549900055,\n",
       " \"35001643 - M83 - Hurry Up, We're Dreaming - Splendor.m4a.wav\": 0.18010924756526947,\n",
       " '30349463 - Led Zeppelin - Led Zeppelin II (Deluxe Edition) - Ramble On (Remaster).m4a.wav': 0.17388413846492767,\n",
       " '49812280 - Jean-Michel Jarre - Houston - Lyon 1986 - Ethnicolor.m4a.wav': 0.17112328112125397,\n",
       " '75194843 - Arcade Fire - Funeral - Neighborhood #1 (Tunnels).m4a.wav': 0.1699204295873642,\n",
       " '58990512 - Radiohead - OK Computer - Paranoid Android.m4a.wav': 0.1677798181772232,\n",
       " '55391583 - Pink Floyd - A Foot in the Door- The Best of Pink Floyd - Comfortably Numb.m4a.wav': 0.16216595470905304,\n",
       " '205001701 - funkadelic - Maggot Brain - Maggot Brain.m4a.wav': 0.11376433819532394}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.perf_counter_ns()\n",
    "\n",
    "#values = rate_file(\"addict11-loved-tracks_ana_results.csv\")\n",
    "values = rate_file(\"my_fun_playlist.csv\")\n",
    "\n",
    "end = time.perf_counter_ns()\n",
    "print(f\"Testing took: {(end - start)/1000000}ms\")\n",
    "dict(sorted(values.items(), key=lambda x: -x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f64e49-0433-4383-954c-e684afa0a00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index[2237] : 0.0323 vs 0.0247\n"
     ]
    }
   ],
   "source": [
    "#test_model(2237)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205992e4-4c5f-4b79-9513-1943a7b41849",
   "metadata": {},
   "source": [
    "# Useless stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "23badfb6-5af8-4dca-8fcc-8b60f967c5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'********'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"*\"*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c506d40-ee06-4b5c-b14c-552dd8abf35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_func(config):\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    lr = config[\"lr\"]\n",
    "    epochs = config[\"epochs\"]\n",
    "\n",
    "    worker_batch_size = 2\n",
    "    #worker_batch_size = batch_size // session.get_world_size()\n",
    "\n",
    "    # Create data loaders.\n",
    "    train_dataloader = DataLoader(training_data, batch_size=worker_batch_size)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=worker_batch_size)\n",
    "\n",
    "    train_dataloader = train.torch.prepare_data_loader(train_dataloader)\n",
    "    test_dataloader = train.torch.prepare_data_loader(test_dataloader)\n",
    "\n",
    "    # Create model.\n",
    "    model = NeuralNetwork()\n",
    "    model = train.torch.prepare_model(model)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        train_epoch(train_dataloader, model, loss_fn, optimizer)\n",
    "        loss = validate_epoch(test_dataloader, model, loss_fn)\n",
    "        session.report(dict(loss=loss))\n",
    "\n",
    "#train_func({\"lr\": 1e-3, \"batch_size\": 64, \"epochs\": 4})\n",
    "#print(f\"Last result: {result.metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f8f21dd1-f93b-45ad-9581-2421ecc287f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(527, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 100),\n",
    "            nn.ReLU(),\n",
    "            #nn.Linear(527, 20),\n",
    "            #nn.ReLU(),\n",
    "            nn.Linear(100, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = F.relu(self.linear_relu_stack[0](x))\n",
    "        #x = F.relu(self.linear_relu_stack[1](x))\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        #logits = nn.functional.softmax(logits, dim=1)\n",
    "        return logits\n",
    "        #return self.linear_relu_stack[2](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fce295ff-599b-4a05-9ab3-507a8b000d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 527, 1])\n",
      "torch.Size([3, 527])\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(3,527,1)\n",
    "print(input_image.size())\n",
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ecf97369-53e5-410a-b142-ef03c2a860fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=527, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=100, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=100, out_features=1, bias=True)\n",
      "    (5): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93f904b-c8c1-46e4-812e-a52d56832070",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
