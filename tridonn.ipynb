{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dee584d8-ce0e-45e3-ad8a-04644d8f2a8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb7e3f28-31cb-43ea-86e6-398a918dddd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#synth_data = open(\"my_10k_synths.csv\", \"r\").readlines()\n",
    "#synth_data = open(\"rating_10k_synths.csv\", \"r\").readlines()\n",
    "synth_data = open(\"arjall_10k_synths.csv\", \"r\").readlines()\n",
    "\n",
    "\n",
    "train_test_percentage = 0.90\n",
    "cutoff = int(train_test_percentage * len(synth_data))\n",
    "\n",
    "# stupid extract data from csv\n",
    "# organized by:\n",
    "#  song_name | num of plays | [values...]\n",
    "lines = [l.replace('\\n', '').split('\\t') for l in synth_data]\n",
    "\n",
    "random.shuffle(lines)\n",
    "\n",
    "# 163 - 259\n",
    "my_x = [[float(i) for i in l[2+163:2+259]] for l in lines]\n",
    "\n",
    "# TODO: put back\n",
    "#my_x = [[float(i) for i in l[2:]] for l in lines]\n",
    "my_y = [float(l[1]) for l in lines]\n",
    "my_y_max = np.amax(my_y)\n",
    "\n",
    "my_y = [[(y/my_y_max)**(0.4)] for y in my_y]\n",
    "\n",
    "# splice dataset\n",
    "train_x = my_x[:cutoff]\n",
    "train_y = my_y[:cutoff]\n",
    "test_x = my_x[cutoff:]\n",
    "test_y = my_y[cutoff:]\n",
    "\n",
    "# prepare tensors\n",
    "tensor_train_x = torch.Tensor(train_x) # transform to torch tensor\n",
    "tensor_train_y = torch.Tensor(train_y)\n",
    "tensor_test_x = torch.Tensor(test_x) # transform to torch tensor\n",
    "tensor_test_y = torch.Tensor(test_y)\n",
    "\n",
    "train_dataset = TensorDataset(tensor_train_x,tensor_train_y) # create your datset\n",
    "train_dataloader = DataLoader(train_dataset) # create your dataloader\n",
    "test_dataset = TensorDataset(tensor_test_x,tensor_test_y) # create your datset\n",
    "test_dataloader = DataLoader(test_dataset) # create your dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c281a90b-0c38-4f2e-8830-ab78d2cac9ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.615e+03, 3.021e+03, 1.464e+03, 9.040e+02, 7.020e+02, 5.840e+02,\n",
       "        4.210e+02, 3.340e+02, 2.370e+02, 1.560e+02, 1.090e+02, 8.100e+01,\n",
       "        5.000e+01, 2.900e+01, 1.200e+01, 1.000e+01, 9.000e+00, 1.000e+00,\n",
       "        3.000e+00, 2.000e+00]),\n",
       " array([2.94787753e-04, 5.02800484e-02, 1.00265309e-01, 1.50250570e-01,\n",
       "        2.00235830e-01, 2.50221091e-01, 3.00206351e-01, 3.50191612e-01,\n",
       "        4.00176873e-01, 4.50162133e-01, 5.00147394e-01, 5.50132654e-01,\n",
       "        6.00117915e-01, 6.50103176e-01, 7.00088436e-01, 7.50073697e-01,\n",
       "        8.00058958e-01, 8.50044218e-01, 9.00029479e-01, 9.50014739e-01,\n",
       "        1.00000000e+00]),\n",
       " <BarContainer object of 20 artists>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 1, sharey=True, tight_layout=True)\n",
    "\n",
    "# We can set the number of bins with the *bins* keyword argument.\n",
    "axs.hist([float(l[0]) for l in my_y], bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e31de980-ba60-49c8-b1dd-402b2183af69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# evaluate a single tensor\n",
    "def test_model(target):\n",
    "    #X = torch.rand(1, 527, 1, device=device)\n",
    "    #target = cutoff + 1\n",
    "    X = torch.tensor(my_x[target])\n",
    "    start = time.perf_counter_ns()\n",
    "    #print(X.shape)\n",
    "    logits = model(X)\n",
    "    end = time.perf_counter_ns()\n",
    "    print(f\"Testing took: {(end - start)/1000000}ms\")\n",
    "    print(f\"index[{target}] : {logits[0]:>0.4f} vs {my_y[target][0]:>0.4f}\")\n",
    "    #print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c6bd177-7f67-4efa-967c-1c00df7720d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def describe_model(model):\n",
    "    print(f\"Model structure: {model}\\n\\n\")\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d16f3437-e0b8-45a0-b1ef-a4528285764a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #if batch % 1 == 0:\n",
    "        loss, current = loss.item(), batch * len(X)\n",
    "        #print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "#pdist = torch.nn.PairwiseDistance(p=2)\n",
    "def validate_epoch(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset) // int(1)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct, errors = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            #print(f\"Got pred: {pred.sum().item()}\\tfor y: {y[0]}\")\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            errors += (abs(pred.sum().item() - y[0]))\n",
    "    test_loss /= num_batches\n",
    "    errors /= size\n",
    "    correct = 1 - errors\n",
    "    if progress % 1 == 0 or progress == 0:\n",
    "        result = str(\n",
    "            f\"Epoch {str(progress).zfill(2)}  \"\n",
    "            #f\"Accuracy: {(100 * correct):>0.1f}%  \"\n",
    "            f\"Avg loss: {test_loss:>8f}  [{'X'*int(50*correct)}{'-'*int(50*(1-correct))}]\"\n",
    "        )\n",
    "        print(result)\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b9e8209-bd91-413e-b4c3-1e78d719c973",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def export_model(expmodel):\n",
    "    dummy_input = torch.randn(1, 1, 96)\n",
    "    torch.onnx.export(expmodel,\n",
    "                 dummy_input,\n",
    "                 \"tridonn.onnx\",\n",
    "                 verbose=True,\n",
    "                 input_names=[\"dense1\"],\n",
    "                 output_names=[\"outact\"],\n",
    "                 export_params=True,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68c1588c-f82c-4cd7-8e72-36424197130a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rate_file(filename):\n",
    "    rate_file = open(filename, \"r\").readlines()\n",
    "    rate_lines = [l.replace('\\n', '').split('\\t') for l in rate_file]\n",
    "\n",
    "    # 163\n",
    "    my_test_x = [[float(i) for i in l[1+163:1+259]] for l in rate_lines[1:]]\n",
    "    song_names = [l[0] for l in rate_lines[1:]]\n",
    "    \n",
    "    #print(\"Song ratings: [0-1]\")\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(len(my_test_x)):\n",
    "            X = torch.tensor(my_test_x[i])\n",
    "            song_name = song_names[i].split('/')[-1]\n",
    "            logits = model(X)\n",
    "            #end = time.perf_counter_ns()\n",
    "            #print(f\"Testing took: {(end - start)/1000000}ms\")\n",
    "            #print(f\"index[{target}] : {logits[0]:>0.4f} vs {my_y[target]:>0.4f}\")\n",
    "            results[song_name] = float(logits[0])\n",
    "\n",
    "            #print(f\"{song_name} = {logits[0]:>0.4f}\")\n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3dd17e2a-0ef8-4ebc-a06b-c9e7af429ae5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      "Testing took: 0.580874ms\n",
      "index[41] : -0.2096 vs 0.2247\n",
      "Epoch 00  Avg loss: 0.155716  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX------------------]\n",
      "\n",
      "Training:\n",
      "Epoch 01  Avg loss: 0.018046  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX-----]\n",
      "0.212254: 35410166 - Galantis - Runaway (U & I) - Runaway (U & I).m4a.wav\n",
      "0.192383: 3670232 - Passion Pit - Manners - Sleepyhead.m4a.wav\n",
      "0.183075: 47696790 - Tame Impala - Currents - Nangs.m4a.wav\n",
      "0.175602: 245042536 - Childish Gambino - -Awaken, My Love!- - Me and Your Mama.m4a.wav\n",
      "0.174650: 74886176 - Portugal. The Man - Woodstock - Tidal Wave.m4a.wav \n",
      "\n",
      "0.094346: 3209964 - Deltron 3030 - Deltron 3030 - 3030.m4a.wav\n",
      "0.093226: 81466340 - Columbine - Clubbing For Columbine - Les prÃ©lis.m4a.wav\n",
      "0.075025: 209237077 - J. Cole - 2014 Forest Hills Drive - G.O.M.D.m4a.wav\n",
      "0.068903: 64230759 - Like - Songs Made While High - Mushroom Clouds.m4a.wav\n",
      "0.066917: 32823114 - Underworld - 1992 - 2012 - Born Slippy (Nuxx).m4a.wav \n",
      "\n",
      "Epoch 02  Avg loss: 0.017980  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX-----]\n",
      "Epoch 03  Avg loss: 0.017946  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX-----]\n",
      "Epoch 04  Avg loss: 0.017965  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX-----]\n",
      "Epoch 05  Avg loss: 0.018003  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX-----]\n",
      "Epoch 06  Avg loss: 0.017955  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX-----]\n",
      "Epoch 07  Avg loss: 0.017916  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX-----]\n",
      "Epoch 08  Avg loss: 0.017879  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX-----]\n",
      "Epoch 09  Avg loss: 0.017843  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX-----]\n",
      "Epoch 10  Avg loss: 0.017831  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX-----]\n",
      "Epoch 11  Avg loss: 0.017835  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX-----]\n",
      "Epoch 12  Avg loss: 0.017881  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX-----]\n",
      "Epoch 13  Avg loss: 0.017846  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX-----]\n",
      "Epoch 14  Avg loss: 0.017861  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX-----]\n",
      "Epoch 15  Avg loss: 0.017869  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX-----]\n",
      "Epoch 16  Avg loss: 0.017909  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX-----]\n",
      "Epoch 17  Avg loss: 0.017895  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX-----]\n",
      "Epoch 18  Avg loss: 0.017901  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX-----]\n",
      "Epoch 19  Avg loss: 0.017908  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX-----]\n",
      "Epoch 20  Avg loss: 0.017913  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX-----]\n",
      "Epoch 21  Avg loss: 0.017914  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX-----]\n",
      "0.259564: 35410166 - Galantis - Runaway (U & I) - Runaway (U & I).m4a.wav\n",
      "0.212785: 47696790 - Tame Impala - Currents - Nangs.m4a.wav\n",
      "0.205945: 68266840 - HOMESHAKE - Midnight Snack - Faded.m4a.wav\n",
      "0.203842: 61325600 - M83 - Do It, Try It (Remixes) - Do It, Try It.m4a.wav\n",
      "0.201929: 85108589 - Digitalism - Zdar C1u6 - Holograms.m4a.wav \n",
      "\n",
      "0.076852: 3209964 - Deltron 3030 - Deltron 3030 - 3030.m4a.wav\n",
      "0.066138: 209237077 - J. Cole - 2014 Forest Hills Drive - G.O.M.D.m4a.wav\n",
      "0.063142: 64230759 - Like - Songs Made While High - Mushroom Clouds.m4a.wav\n",
      "0.062299: 55391583 - Pink Floyd - A Foot in the Door- The Best of Pink Floyd - Comfortably Numb.m4a.wav\n",
      "0.008894: 32823114 - Underworld - 1992 - 2012 - Born Slippy (Nuxx).m4a.wav \n",
      "\n",
      "Training took: 126050.214824ms\n",
      "\n",
      "Testing:\n",
      "Testing took: 0.148701ms\n",
      "index[41] : 0.1143 vs 0.2247\n",
      "Testing took: 0.292183ms\n",
      "91991\n"
     ]
    }
   ],
   "source": [
    "#model = NeuralNetwork().to(device)\n",
    "\"\"\"\n",
    "N0 = 527\n",
    "N1 = 1000\n",
    "N2 = 1\n",
    "#NX = 1\n",
    "\n",
    "model = nn.Sequential(OrderedDict([\n",
    "    ('dense1', nn.Linear(N0, N1)),\n",
    "    ('act1', nn.ReLU()),\n",
    "    ('dense2', nn.Linear(N1, N2)),\n",
    "    #('act2', nn.ReLU()),\n",
    "    #('output', nn.Linear(N2, NX)),\n",
    "    ('outact', nn.Sigmoid()),\n",
    "]))\n",
    "\"\"\"\n",
    "SN0 = 96\n",
    "\n",
    "N0 = 96\n",
    "N1 = 192\n",
    "N2 = 20\n",
    "N3 = 1\n",
    "NX = 1\n",
    "\n",
    "model = nn.Sequential(OrderedDict([\n",
    "    ('dense1', nn.Linear(N0, N1, True)),\n",
    "    ('act1', nn.Tanh()),\n",
    "    ('dense2', nn.Linear(N1, N2, True)),\n",
    "    ('act2', nn.Tanh()),\n",
    "    #('dropout', nn.Dropout()),\n",
    "    #('dense3', nn.Linear(N1, N1, True)),\n",
    "    #('act3', nn.Tanh()),\n",
    "    #('dense4', nn.Linear(N1, N2, True)),\n",
    "    #('act4', nn.Tanh()),\n",
    "    \n",
    "    #('dense3', nn.Linear(N15, N2, True)),\n",
    "    #('act3', nn.Tanh()),\n",
    "    ('output', nn.Linear(N2, N3)),\n",
    "    #('act3', nn.ReLU()),\n",
    "    #('output2', nn.Linear(N3, NX)),\n",
    "    #('outact', nn.Sigmoid()),\n",
    "]))\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.02, momentum=0.95)\n",
    "epochs = 21\n",
    "progress = 0\n",
    "\n",
    "target = 41\n",
    "\n",
    "# before training (sanity check)\n",
    "print(\"Before:\")\n",
    "test_model(target)\n",
    "\n",
    "loss = validate_epoch(test_dataloader, model, loss_fn)\n",
    "\n",
    "train_time = 0\n",
    "print(\"\\nTraining:\")\n",
    "\n",
    "should_eval = True\n",
    "\n",
    "for i in range(epochs):\n",
    "    progress += 1\n",
    "    start = time.perf_counter_ns()\n",
    "    #train_dataloader = DataLoader(train_dataset, shuffle=True) # create your dataloader\n",
    "\n",
    "    train_epoch(train_dataloader, model, loss_fn, optimizer)\n",
    "    train_time += time.perf_counter_ns() - start\n",
    "    loss = validate_epoch(test_dataloader, model, loss_fn)\n",
    "    \n",
    "    #print(loss)\n",
    "    \n",
    "    should_eval = i % 20 == 0\n",
    "    \n",
    "    # eval\n",
    "    if should_eval:\n",
    "        values = rate_file(\"my_fun_playlist.csv\")\n",
    "        print('\\n'.join([f\"{f[1]:>6f}: {f[0]}\" for f in sorted(values.items(), key=lambda x: -x[1])[:5]]), \"\\n\")\n",
    "        print('\\n'.join([f\"{f[1]:>6f}: {f[0]}\" for f in sorted(values.items(), key=lambda x: -x[1])[-5:]]), \"\\n\")\n",
    "    #session.report(dict(loss=loss))\n",
    "\n",
    "print(f\"Training took: {(train_time)/1000000}ms\")\n",
    "\n",
    "print(\"\\nTesting:\")\n",
    "start = time.perf_counter_ns()\n",
    "test_model(target)\n",
    "end = time.perf_counter_ns()\n",
    "print(f\"Testing took: {(end - start)/1000000}ms\")\n",
    "    \n",
    "torch.save(model.state_dict(), 'tridonn')\n",
    "print(os.path.getsize('tridonn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "be9df99f-b383-4269-ba2a-9d132e7806e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%dense1 : Float(1, 1, 96, strides=[96, 96, 1], requires_grad=0, device=cpu),\n",
      "      %dense1.bias : Float(192, strides=[1], requires_grad=1, device=cpu),\n",
      "      %dense2.bias : Float(20, strides=[1], requires_grad=1, device=cpu),\n",
      "      %output.bias : Float(1, strides=[1], requires_grad=1, device=cpu),\n",
      "      %onnx::MatMul_19 : Float(96, 192, strides=[1, 96], requires_grad=0, device=cpu),\n",
      "      %onnx::MatMul_20 : Float(192, 20, strides=[1, 192], requires_grad=0, device=cpu),\n",
      "      %onnx::MatMul_21 : Float(20, 1, strides=[1, 20], requires_grad=0, device=cpu)):\n",
      "  %/dense1/MatMul_output_0 : Float(1, 1, 192, strides=[192, 192, 1], device=cpu) = onnx::MatMul[onnx_name=\"/dense1/MatMul\"](%dense1, %onnx::MatMul_19), scope: torch.nn.modules.container.Sequential::/torch.nn.modules.linear.Linear::dense1 # /home/tristan/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %/dense1/Add_output_0 : Float(1, 1, 192, strides=[192, 192, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/dense1/Add\"](%dense1.bias, %/dense1/MatMul_output_0), scope: torch.nn.modules.container.Sequential::/torch.nn.modules.linear.Linear::dense1 # /home/tristan/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %/act1/Tanh_output_0 : Float(1, 1, 192, strides=[192, 192, 1], requires_grad=1, device=cpu) = onnx::Tanh[onnx_name=\"/act1/Tanh\"](%/dense1/Add_output_0), scope: torch.nn.modules.container.Sequential::/torch.nn.modules.activation.Tanh::act1 # /home/tristan/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py:358:0\n",
      "  %/dense2/MatMul_output_0 : Float(1, 1, 20, strides=[20, 20, 1], device=cpu) = onnx::MatMul[onnx_name=\"/dense2/MatMul\"](%/act1/Tanh_output_0, %onnx::MatMul_20), scope: torch.nn.modules.container.Sequential::/torch.nn.modules.linear.Linear::dense2 # /home/tristan/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %/dense2/Add_output_0 : Float(1, 1, 20, strides=[20, 20, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/dense2/Add\"](%dense2.bias, %/dense2/MatMul_output_0), scope: torch.nn.modules.container.Sequential::/torch.nn.modules.linear.Linear::dense2 # /home/tristan/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %/act2/Tanh_output_0 : Float(1, 1, 20, strides=[20, 20, 1], requires_grad=1, device=cpu) = onnx::Tanh[onnx_name=\"/act2/Tanh\"](%/dense2/Add_output_0), scope: torch.nn.modules.container.Sequential::/torch.nn.modules.activation.Tanh::act2 # /home/tristan/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py:358:0\n",
      "  %/output/MatMul_output_0 : Float(1, 1, 1, strides=[1, 1, 1], device=cpu) = onnx::MatMul[onnx_name=\"/output/MatMul\"](%/act2/Tanh_output_0, %onnx::MatMul_21), scope: torch.nn.modules.container.Sequential::/torch.nn.modules.linear.Linear::output # /home/tristan/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %/output/Add_output_0 : Float(1, 1, 1, strides=[1, 1, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/output/Add\"](%output.bias, %/output/MatMul_output_0), scope: torch.nn.modules.container.Sequential::/torch.nn.modules.linear.Linear::output # /home/tristan/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:114:0\n",
      "  %outact : Float(1, 1, 1, strides=[1, 1, 1], requires_grad=1, device=cpu) = onnx::Sigmoid[onnx_name=\"/outact/Sigmoid\"](%/output/Add_output_0), scope: torch.nn.modules.container.Sequential::/torch.nn.modules.activation.Sigmoid::outact # /home/tristan/.local/lib/python3.10/site-packages/torch/nn/modules/activation.py:294:0\n",
      "  return (%outact)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# export for onnx\n",
    "export_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "fe195396-3199-433e-a1b9-c500159e4628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02  Accuracy: 60.1%  Avg loss: 0.398816  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX-------------------]\n",
      "\n",
      "Training 50 10:\n",
      "Epoch 02  Accuracy: 88.2%  Avg loss: 0.117912  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX-----]\n",
      "Epoch 02  Accuracy: 94.5%  Avg loss: 0.055056  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX--]\n",
      "Epoch 02  Accuracy: 94.6%  Avg loss: 0.054162  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX--]\n",
      "Epoch 02  Accuracy: 94.6%  Avg loss: 0.054163  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX--]\n",
      "Training took: 11129.644717ms\n",
      "Testing took: 0.384089ms\n",
      "index[41] : 0.1846 vs 0.0820\n",
      "Testing took: 0.487468ms\n",
      "Epoch 02  Accuracy: 59.8%  Avg loss: 0.401754  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXX--------------------]\n",
      "\n",
      "Training 50 110:\n",
      "Epoch 02  Accuracy: 92.0%  Avg loss: 0.080398  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX----]\n",
      "Epoch 02  Accuracy: 94.6%  Avg loss: 0.054182  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX--]\n",
      "Epoch 02  Accuracy: 94.6%  Avg loss: 0.054164  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX--]\n",
      "Epoch 02  Accuracy: 94.6%  Avg loss: 0.054165  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX--]\n",
      "Training took: 11184.852568ms\n",
      "Testing took: 0.476434ms\n",
      "index[41] : 0.1846 vs 0.0820\n",
      "Testing took: 0.590181ms\n",
      "Epoch 02  Accuracy: 58.7%  Avg loss: 0.412802  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXX--------------------]\n",
      "\n",
      "Training 50 210:\n",
      "Epoch 02  Accuracy: 93.2%  Avg loss: 0.067526  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX---]\n",
      "Epoch 02  Accuracy: 94.6%  Avg loss: 0.054174  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX--]\n",
      "Epoch 02  Accuracy: 94.6%  Avg loss: 0.054174  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX--]\n",
      "Epoch 02  Accuracy: 94.6%  Avg loss: 0.054172  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX--]\n",
      "Training took: 11686.991254ms\n",
      "Testing took: 0.453436ms\n",
      "index[41] : 0.1846 vs 0.0820\n",
      "Testing took: 0.562543ms\n",
      "Epoch 02  Accuracy: 60.5%  Avg loss: 0.394876  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXX-------------------]\n",
      "\n",
      "Training 250 10:\n",
      "Epoch 02  Accuracy: 85.1%  Avg loss: 0.149415  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX-------]\n",
      "Epoch 02  Accuracy: 93.7%  Avg loss: 0.062862  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX---]\n",
      "Epoch 02  Accuracy: 94.6%  Avg loss: 0.054244  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX--]\n",
      "Epoch 02  Accuracy: 94.6%  Avg loss: 0.054181  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX--]\n",
      "Training took: 11842.319372ms\n",
      "Testing took: 0.424242ms\n",
      "index[41] : 0.1846 vs 0.0820\n",
      "Testing took: 0.526978ms\n",
      "Epoch 02  Accuracy: 59.7%  Avg loss: 0.403063  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXX--------------------]\n",
      "\n",
      "Training 250 110:\n",
      "Epoch 02  Accuracy: 88.6%  Avg loss: 0.114273  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX-----]\n",
      "Epoch 02  Accuracy: 94.5%  Avg loss: 0.054562  [XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX--]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[136], line 69\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n1 \u001b[38;5;129;01min\u001b[39;00m n1_range:\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m n2 \u001b[38;5;129;01min\u001b[39;00m n2_range:\n\u001b[0;32m---> 69\u001b[0m         \u001b[43mhyper_train_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m results\u001b[38;5;241m.\u001b[39mclose()\n",
      "Cell \u001b[0;32mIn[136], line 41\u001b[0m, in \u001b[0;36mhyper_train_step\u001b[0;34m(N1, N2)\u001b[0m\n\u001b[1;32m     39\u001b[0m progress \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     40\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter_ns()\n\u001b[0;32m---> 41\u001b[0m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m train_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter_ns() \u001b[38;5;241m-\u001b[39m start\n\u001b[1;32m     43\u001b[0m loss \u001b[38;5;241m=\u001b[39m validate_epoch(test_dataloader, model, loss_fn)\n",
      "Cell \u001b[0;32mIn[130], line 12\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[1;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 12\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "res_name = \"instances_my\"\n",
    "\n",
    "results = open(f\"{res_name}_results.txt\", \"w\")\n",
    "\n",
    "#os.mkdir(res_name)\n",
    "\n",
    "def hyper_train_step(N1, N2):\n",
    "    N0 = 527\n",
    "    NX = 1\n",
    "\n",
    "    model = nn.Sequential(OrderedDict([\n",
    "        ('dense1', nn.Linear(N0, N1)),\n",
    "        ('act1', nn.ReLU()),\n",
    "        ('dense2', nn.Linear(N1, N2)),\n",
    "        ('act2', nn.ReLU()),\n",
    "        ('output', nn.Linear(N2, NX)),\n",
    "        ('outact', nn.Sigmoid()),\n",
    "    ]))\n",
    "\n",
    "    loss_fn = nn.L1Loss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.0008)\n",
    "    epochs = 4\n",
    "    progress = 0\n",
    "\n",
    "    target = 41\n",
    "\n",
    "    # before training (sanity check)\n",
    "    #print(\"Before:\")\n",
    "    #test_model(target)\n",
    "\n",
    "    loss = validate_epoch(test_dataloader, model, loss_fn)\n",
    "\n",
    "    train_time = 0\n",
    "    print(f\"\\nTraining {N1} {N2}:\")\n",
    "\n",
    "    should_eval = False\n",
    "\n",
    "    for i in range(epochs):\n",
    "        progress += 1\n",
    "        start = time.perf_counter_ns()\n",
    "        train_epoch(train_dataloader, model, loss_fn, optimizer)\n",
    "        train_time += time.perf_counter_ns() - start\n",
    "        loss = validate_epoch(test_dataloader, model, loss_fn)\n",
    "\n",
    "        results.write(f\"{N1} {N2} {loss}\\n\")\n",
    "        \n",
    "        # eval\n",
    "        if should_eval:\n",
    "            values = rate_file(\"my_fun_playlist.csv\")\n",
    "            print('\\n'.join([f\"{f[0]}: {f[1]}\" for f in sorted(values.items(), key=lambda x: -x[1])[:5]]))\n",
    "            print('\\n'.join([f\"{f[0]}: {f[1]}\" for f in sorted(values.items(), key=lambda x: -x[1])[-5:]]))\n",
    "        #session.report(dict(loss=loss))\n",
    "\n",
    "    print(f\"Training took: {(train_time)/1000000}ms\")\n",
    "\n",
    "    #print(\"\\nTesting:\")\n",
    "    start = time.perf_counter_ns()\n",
    "    test_model(target)\n",
    "    end = time.perf_counter_ns()\n",
    "    print(f\"Testing took: {(end - start)/1000000}ms\")\n",
    "\n",
    "    torch.save(model.state_dict(), f'{res_name}/tridonn_{N1}_{N2}')\n",
    "\n",
    "n1_range = range(50, 2550, 200)\n",
    "n2_range = range(10, 220, 100)\n",
    "\n",
    "for n1 in n1_range:\n",
    "    for n2 in n2_range:\n",
    "        hyper_train_step(n1, n2)\n",
    "        \n",
    "results.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99081a14-7c72-412f-b79f-9a0d774ca3e7",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc888b0-0478-4d6c-b1bb-3b09c6e0c459",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter_ns()\n",
    "\n",
    "#values = rate_file(\"addict11-loved-tracks_ana_results.csv\")\n",
    "values = rate_file(\"my_fun_playlist.csv\")\n",
    "\n",
    "end = time.perf_counter_ns()\n",
    "print(f\"Testing took: {(end - start)/1000000}ms\")\n",
    "dict(sorted(values.items(), key=lambda x: -x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f64e49-0433-4383-954c-e684afa0a00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index[2237] : 0.0323 vs 0.0247\n"
     ]
    }
   ],
   "source": [
    "#test_model(2237)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1c701d-fe63-44e1-9e0d-dcca33174bf6",
   "metadata": {},
   "source": [
    "## Hyperparameter stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205992e4-4c5f-4b79-9513-1943a7b41849",
   "metadata": {},
   "source": [
    "# Useless stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "23badfb6-5af8-4dca-8fcc-8b60f967c5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'********'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"*\"*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c506d40-ee06-4b5c-b14c-552dd8abf35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_func(config):\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    lr = config[\"lr\"]\n",
    "    epochs = config[\"epochs\"]\n",
    "\n",
    "    worker_batch_size = 2\n",
    "    #worker_batch_size = batch_size // session.get_world_size()\n",
    "\n",
    "    # Create data loaders.\n",
    "    train_dataloader = DataLoader(training_data, batch_size=worker_batch_size)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=worker_batch_size)\n",
    "\n",
    "    train_dataloader = train.torch.prepare_data_loader(train_dataloader)\n",
    "    test_dataloader = train.torch.prepare_data_loader(test_dataloader)\n",
    "\n",
    "    # Create model.\n",
    "    model = NeuralNetwork()\n",
    "    model = train.torch.prepare_model(model)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        train_epoch(train_dataloader, model, loss_fn, optimizer)\n",
    "        loss = validate_epoch(test_dataloader, model, loss_fn)\n",
    "        session.report(dict(loss=loss))\n",
    "\n",
    "#train_func({\"lr\": 1e-3, \"batch_size\": 64, \"epochs\": 4})\n",
    "#print(f\"Last result: {result.metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f8f21dd1-f93b-45ad-9581-2421ecc287f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(527, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 100),\n",
    "            nn.ReLU(),\n",
    "            #nn.Linear(527, 20),\n",
    "            #nn.ReLU(),\n",
    "            nn.Linear(100, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = F.relu(self.linear_relu_stack[0](x))\n",
    "        #x = F.relu(self.linear_relu_stack[1](x))\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        #logits = nn.functional.softmax(logits, dim=1)\n",
    "        return logits\n",
    "        #return self.linear_relu_stack[2](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fce295ff-599b-4a05-9ab3-507a8b000d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 527, 1])\n",
      "torch.Size([3, 527])\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(3,527,1)\n",
    "print(input_image.size())\n",
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ecf97369-53e5-410a-b142-ef03c2a860fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=527, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=100, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=100, out_features=1, bias=True)\n",
      "    (5): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93f904b-c8c1-46e4-812e-a52d56832070",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
